from fastapi import FastAPI, File, UploadFile, Form, Request
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
# from fastapi.requests import Request
from pydantic import BaseModel
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.lib.utils import ImageReader
from openai import OpenAI
from backend.s3_uploader import upload_image_to_epsondest
import google.generativeai as genai
from PIL import Image
import uuid
import os

import os, sys
print("CWD =", os.getcwd())
print("PYTHONPATH =", sys.path)
print("backend/ content =", os.listdir("backend"))

#åˆå§‹åŒ– OpenAI and Gemini
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
print("GEMINI_API_KEY:", os.getenv("GEMINI_API_KEY")[:6])

app = FastAPI()
UPLOAD_DIR = "uploads"
PDF_DIR = "pdf_files"
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(PDF_DIR, exist_ok=True)

#è¨˜æ†¶Gemini å°è©±æ­·å²
chat_history = []

# API ï¼šä¸Šå‚³åœ–ç‰‡
app.add_middleware(
    CORSMiddleware,
    # allow_origins=["http://localhost:5173","https://epson-hey-echo.onrender.com"],  # å…è¨±å‰ç«¯è«‹æ±‚ã€‚èˆŠçš„: http://localhost:5173
    allow_origins=["*"],#ç¢ºå®šæ­¤æ–¹æ³•å¯è¡Œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
@app.get("/")
async def root():
    return {"message":"Backend is alive !!!"}

#test: geminiå’Œgpt
@app.get("/test-gemini")
async def test_gemini():
    try:
        model = genai.GenerativeModel("gemini-2.0-flash")
        response = model.generate_content("è«‹æä¾›ä¸€å€‹é©åˆç”¨ AI ç•«å‡ºçš„æœ‰è¶£å ´æ™¯")
        return {"gemini_response": response.text.strip()}
    except Exception as e:
        return {"error": str(e)}

@app.get("/test-gpt")
async def test_gpt():
    try:
        response = client.chat.completions.create(
            model="gpt-4-1106-preview",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯æç¤ºè©å°ˆå®¶ï¼Œè«‹ç”¨è‹±æ–‡å¯«ä¸€å€‹é©åˆ DALLÂ·E åœ–åƒç”Ÿæˆçš„ prompt"},
                {"role": "user", "content": "æˆ‘æƒ³ç•«ä¸€éš»æˆ´è‘—å¤ªç©ºå¸½çš„æŸ´çŠ¬ç«™åœ¨æœˆçƒä¸Š"}
            ]
        )
        return {"gpt_prompt": response.choices[0].message.content.strip()}
    except Exception as e:
        return {"error": str(e)}
    
# æ¸¬è©¦chatbot: gemini+gpt
# #é–‹å ´ç™½
# @app.get("/onboarding")
# async def onboarding():
#     return {
#         "messages": [
#             {
#                 "role": "assistant",
#                 "type": "text",
#                 "content": "å—¨æˆ‘æ˜¯ä½ çš„ AI è¨­è¨ˆå¸«ï¼ŒEcho ğŸ¨ è«‹å•ä½ ä»Šå¤©æƒ³è¦è¨­è¨ˆä»€éº¼å‘¢ï¼Ÿ"
#             },
#             {
#                 "role": "assistant",
#                 "type": "text",
#                 "content": "ä½ å¯ä»¥é¸æ“‡ï¼š\n1ï¸âƒ£ AI åœ–åƒå‰µä½œ\n2ï¸âƒ£ æ’ç‰ˆæˆ PDF\n3ï¸âƒ£ çµ¦æˆ‘éˆæ„Ÿï¼Œæˆ‘å¹«ä½ æƒ³\n\nç›´æ¥è¼¸å…¥æ•¸å­—æˆ–æè¿°ä¹Ÿå¯ä»¥å–”ï¼"
#             },
#             {
#                 "role": "assistant",
#                 "type": "text",
#                 "content": "å¦‚æœä½ æœ‰åœ–ç‰‡æƒ³ä¸€èµ·ç”¨ï¼Œä¹Ÿå¯ä»¥ä¸Šå‚³ï¼Œæˆ‘æœƒå¹«ä½ åŠ ä¸Šæ–‡å­—ã€è¨­è¨ˆé¢¨æ ¼ï¼Œå†è¼¸å‡ºæˆæ¼‚äº®çš„æ’ç‰ˆå”·ï¼"
#             }
#         ]
#     }

@app.post("/multi-dialogue-to-image")
async def generate_prompt(req: Request):
    try:
        data = await req.json()
        messages = data.get("messages", [])

        # Step 1: èˆ‡Geminiå°è©±
        combined_text = ""
        for msg in messages:
            if msg["type"] == "text":
                role = "User" if msg["role"] == "user" else "model"
                chat_history.append({"role": role, "parts": [msg["content"]]})
                image_url = data.get("image_url")
                # combined_text += f"{role}: {msg['content']}\n"

        model = genai.GenerativeModel('gemini-2.0-flash')
        chat = model.start_chat(history = chat_history)
        
        response = chat.send_message("ä½ æ˜¯å°ˆé–€è¨­è¨ˆæˆ¿ä»²æ–‡å®£çš„è¨­è¨ˆå¸«ã€‚è«‹ç”¨è‡ªç„¶çš„èŠå¤©èªæ°£ï¼Œå‘Šè¨´æˆ‘ä½ æœƒæ€éº¼è¨­è¨ˆé€™å¼µæˆ¿ä»²å®£å‚³æµ·å ±ï¼Œå¯ä»¥æåˆ°ä¸»é«”ï¼ˆåƒæ˜¯å»ºç¯‰ç‰©ã€è¡—æ™¯ï¼‰ã€æ°£æ°›ã€è‰²èª¿å’Œè¦–è¦ºé‡é»ã€‚ç°¡çŸ­æè¿°å°±å¥½ï¼Œä¸ç”¨æ¢åˆ—ã€‚")
        idea_description = response.text.strip()
        chat_history.append({"role": "model", "parts": [idea_description]})
        print("[Gemini idea]", idea_description)
        
        segments = [s.strip() for s in idea_description.replace("\n", "").split("ã€‚") if s.strip()]
        text_messages = [{"role": "assistant", "type": "text", "content": s + "ã€‚"} for s in segments] #å›è¤‡è¨Šæ¯
        image_url = data.get("image_url")
        if image_url:
            text_messages.insert(0,{
                "role": "user",
                "type": "image",
                "image_url": image_url
            })
        
        # å¦‚æœåŒ…å«æŒ‡å®šé—œéµèªå¥ï¼Œèµ°ã€Œåˆæˆæˆ¿ä»²æµ·å ±é‚è¼¯ã€
        trigger_keywords = [
            "åˆæˆ", "å»ºç¯‰","å®£å‚³å–®"
        ]
        # å…ˆæ‰¾å‡ºä½¿ç”¨è€…æœ€å¾Œä¸€å‰‡æ–‡å­—è¨Šæ¯
        user_texts = [m["content"] for m in messages if m["role"] == "user" and m["type"] == "text"]
        user_all_text = "".join(user_texts)

        matched = any(keyword in user_all_text for keyword in trigger_keywords)
        print("[Triggeråˆ¤æ–· user_all_text]:", user_all_text)
        print("[Trigger æ˜¯å¦è§¸ç™¼]", matched)

        if matched:
            print("[Trigger] é€²å…¥æˆ¿ä»²æµ·å ±åˆæˆåŠŸèƒ½")

            # GPT å¹«å¿™ç”¢æ–‡æ¡ˆ
            title = client.chat.completions.create(
                model="gpt-4-1106-preview",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æˆ¿ä»²å»£å‘Šè¨­è¨ˆå¸«ï¼Œè«‹ç”¢å‡ºä¸€å€‹å¸ç›çš„æˆ¿ä»²ä¸»æ¨™é¡Œï¼Œä¸è¶…é20å­—ï¼Œèªæ°£è‡ªç„¶å£èªã€‚"},
                    {"role": "user", "content": user_all_text}
                ]
            ).choices[0].message.content.strip()

            subtitle = client.chat.completions.create(
                model="gpt-4-1106-preview",
                messages=[
                    {"role": "system", "content": "è«‹è£œä¸€å¥èªªæ˜æ€§å‰¯æ¨™ï¼ˆæœ€å¤š20å­—ï¼‰"},
                    {"role": "user", "content": user_all_text}
                ]
            ).choices[0].message.content.strip()

            cta = client.chat.completions.create(
                model="gpt-4-1106-preview",
                messages=[
                    {"role": "system", "content": "è«‹ç”¢å‡ºä¸€æ®µæˆ¿ä»²å»£å‘Šå¸¸ç”¨çš„è¯çµ¡è³‡è¨Šæ–‡å­—ï¼ˆä¾‹å¦‚ï¼šå‚…æ¨æ·µ 0988-100-122ï¼‰"},
                    {"role": "user", "content": user_all_text}
                ]
            ).choices[0].message.content.strip()

            print("[æ–‡æ¡ˆç”Ÿæˆ]", title, subtitle, cta)

            # ç”¢ç´”è‰²èƒŒæ™¯ï¼ˆç”¨ Pillow ç”¢åœ–ï¼‰
            from PIL import Image, ImageDraw, ImageFont
            import uuid, os
            width, height = 1240, 1754
            bg_color = "#264432"
            bottom_color = "#F8F1D7"
            poster = Image.new("RGB", (width, height), bg_color)
            draw = ImageDraw.Draw(poster)
            draw.rectangle([0, height * 0.75, width, height], fill=bottom_color)

            # ç–Šå»ºç¯‰åœ–
            from io import BytesIO
            import requests

            image_url = data.get("image_url")
            if image_url:
                r = requests.get(image_url)
                fg = Image.open(BytesIO(r.content)).convert("RGBA")

                # resize + paste
                ratio = width * 0.8 / fg.width
                fg_resized = fg.resize((int(fg.width * ratio), int(fg.height * ratio)))
                x = (width - fg_resized.width) // 2
                y = int(height * 0.35 - fg_resized.height / 2)
                poster.paste(fg_resized, (x, y), fg_resized)

            # åŠ ä¸Šæ–‡å­—
            try:
                font_h1 = ImageFont.truetype("arial.ttf", 72)
                font_h2 = ImageFont.truetype("arial.ttf", 40)
                font_cta = ImageFont.truetype("arial.ttf", 36)
            except:
                font_h1 = font_h2 = font_cta = ImageFont.load_default()

            draw.text((80, 60), title, font=font_h1, fill="#F8F1D7")
            draw.text((80, height * 0.75 + 40), subtitle, font=font_h2, fill="#264432")
            draw.text((80, height * 0.75 + 120), cta, font=font_cta, fill="#264432")

            # å„²å­˜åœ–ç‰‡
            fileName = f"{uuid.uuid4().hex}.png"
            filepath = os.path.join(UPLOAD_DIR, fileName)
            poster.save(filepath)
            
            # ä¸Šå‚³ Epson
            from backend.s3_uploader import upload_image_to_epsondest  # æ”¾æœ€ä¸Šé¢ import

            status, image_url = upload_image_to_epsondest(filepath, fileName)
            if status != 200:
                return JSONResponse(content={"error": "åœ–ç‰‡ä¸Šå‚³ Epson å¤±æ•—"}, status_code=500)

            response_messages = text_messages + [
                {"role": "assistant", "type": "image", "image_url": image_url}
            ]
            # å¦‚æœä½¿ç”¨è€…æœ‰ä¸Šå‚³åœ–ç‰‡ï¼Œæ”¾åœ¨æœ€å‰é¢
            if data.get("image_url"):
                response_messages.insert(0, {
                    "role": "user",
                    "type": "image",
                    "image_url": data["image_url"]
                })
            return JSONResponse(content={
                "new_messages": response_messages
            })
        
        # Step 2: ä½¿ç”¨ GPT-4 è½‰æ›ç‚º prompt
        try:
            system_msg = """
            ä½ æ˜¯ä¸€ä½ç†Ÿæ‚‰æˆ¿ä»²å»£å‘Šèˆ‡å»ºç¯‰æ”å½±çš„åœ–åƒæç¤ºè©å·¥ç¨‹å¸«ã€‚æ ¹æ“šè¼¸å…¥å…§å®¹ï¼Œè«‹æ’°å¯«è‹±æ–‡ promptï¼Œä¾› DALLÂ·E åœ–åƒç”Ÿæˆã€‚è«‹å‹™å¿…åŒ…å«æ˜ç¢ºçš„ä¸»é«”ï¼ˆå¦‚å»ºç¯‰ã€è¡—æ™¯ã€æˆ¿å±‹å¤–è§€ï¼‰ï¼Œä»¥åˆ©ç”Ÿæˆé«˜å“è³ªã€å…·ä¸»é«”æ€§çš„åœ–ç‰‡ã€‚

            ã€å…‰ç…§æ•ˆæœã€‘
            Soft lighting (æŸ”å…‰), Hard lighting (ç¡¬å…‰), Backlighting (é€†å…‰), Side lighting (å´å…‰), Silhouette (å‰ªå½±), Diffused light (æ“´æ•£å…‰), Spotlight (èšå…‰), Rim lighting (é‚Šå…‰), Ambient lighting (ç’°å¢ƒå…‰), Tyndall Effect (æ³°å› é”çˆ¾æ•ˆæ‡‰), Rayleigh Scattering (ç‘åˆ©æ•£å°„), God Rays / Crepuscular Rays (è€¶ç©Œå…‰/æš®å…‰å°„ç·š), Bokeh (æ•£æ™¯), Caustics (ç„¦æ•£æ•ˆæœ), Chiaroscuro (æ˜æš—å°æ¯”), Gobo Lighting (æˆˆåšç…§æ˜), Halo Effect (å…‰æšˆæ•ˆæœ), Golden hour (é»ƒé‡‘æ™‚åˆ»)

            ã€è‰²å½©è‰²èª¿ã€‘
            Saturated (é£½å’Œ), Desaturated (å»é£½å’Œ), High Contrast (é«˜å°æ¯”åº¦), Low Contrast (ä½å°æ¯”åº¦), Vibrant (é®®è±”), Muted (æŸ”å’Œ), Warm Tones (æš–è‰²èª¿), Cool Tones (å†·è‰²èª¿), Monochromatic (å–®è‰²èª¿), Duotone (é›™è‰²èª¿), Sepia (æ£•è¤è‰²èª¿), Cross Processing (äº¤å‰æ²–å°), HDR Toning (HDRèª¿è‰²), Tint (è‰²èª¿æ·»åŠ ), Lomo Effect (LOMOæ•ˆæœ), Bleach Bypass (æ¼‚ç™½ç¹é), Cyanotype (è—å°æ³•), Grain / Film Grain (é¡†ç²’æ„Ÿ/è† ç‰‡é¡†ç²’), Analog (é¡æ¯”æ•ˆæœ)

            ã€æ¸²æŸ“èˆ‡è³ªæ„Ÿã€‘
            Polaroid Effect (æ‹ç«‹å¾—æ•ˆæœ), Octane Render (Octaneæ¸²æŸ“å™¨), 4K Resolution (4Kè§£æåº¦), Texture Mapping (ç´‹ç†æ˜ å°„), HDR (High Dynamic Range, é«˜å‹•æ…‹ç¯„åœ), Matte Painting (æ•¸ç¢¼å½©ç¹ª), Glossy Finish (å…‰æ¾¤è¡¨é¢), Roughness / Bump Mapping (ç²—ç³™åº¦/å‡¸èµ·æ˜ å°„), Cinema 4D (C4D), Blender (æ··åˆå™¨), Maya, Arnold Renderer (é˜¿è«¾å¾·æ¸²æŸ“å™¨), V-Ray (V-Rayæ¸²æŸ“å™¨), Substance Painter (Substanceç¹ªç•«å™¨), Quixel Mixer (Quixelæ··åˆå™¨), Houdini (èƒ¡è¿ªå°¼)
            
            ã€æ§‹åœ–æŠ€å·§èˆ‡æ–¹æ³•ã€‘
            Rule of Thirds (ä¸‰åˆ†æ³•å‰‡), Leading Lines (å¼•å°ç·š), Framing (æ¡†æ¶æ³•), Symmetry and Patterns (å°ç¨±èˆ‡åœ–æ¡ˆ), Depth of Field (æ™¯æ·±), Negative Space (è² ç©ºé–“), Golden Ratio (é»ƒé‡‘æ¯”ä¾‹), Focus on Eye Level (æ³¨è¦–é»å±¤æ¬¡), Diagonal Composition (å°è§’ç·šæ§‹åœ–), Juxtaposition (ä¸¦ç½®), Point of View (è¦–é»), Color Contrast (è‰²å½©å°æ¯”), Isolation (å­¤ç«‹), S-Curve (Så‹æ›²ç·š), Frame Within a Frame (æ¡†ä¸­æ¡†), Dynamic Tension (å‹•æ…‹å¼µåŠ›), Balance (å¹³è¡¡), Repetition (é‡è¤‡), Vanishing Point (æ¶ˆå¤±é»), Selective Focus (é¸æ“‡æ€§å°ç„¦), Symmetry and Asymmetry (å°ç¨±èˆ‡ä¸å°ç¨±), High Angle and Low Angle (é«˜è§’åº¦èˆ‡ä½è§’åº¦)

            ã€æ§‹åœ–æŠ€å·§èˆ‡è¦–è§’ã€‘
            Bird's-eye view (é³¥ç°åœ–), Aerial view (ç©ºæ‹è¦–è§’), First-person view (ç¬¬ä¸€äººç¨±è¦–è§’), Third-person view (ç¬¬ä¸‰äººç¨±è¦–è§’), Front (æ­£é¢è¦–è§’), Side (å´é¢è¦–è§’), Top-down (ä¿¯è¦–è¦–è§’), Close-up (è¿‘è·é›¢æ‹æ”), Medium shot (ä¸­è·é›¢æ‹æ”), Wide shot (é è·é›¢æ‹æ”), Wide-angle lens (å»£è§’é¡é ­), Telephoto lens (é•·ç„¦é¡é ­), Fisheye lens (é­šçœ¼é¡é ­), Narrow field of view (çª„è¦–é‡), Wide field of view (å¯¬è¦–é‡), One-point perspective (ä¸€é»é€è¦–), Two-point perspective (å…©é»é€è¦–), Three-point perspective (ä¸‰é»é€è¦–)
            
            è«‹æ³¨æ„ï¼šç”Ÿæˆçš„ prompt æœ€çµ‚æœƒç”¨æ–¼è¨­è¨ˆæˆ¿ä»²æµ·å ±ï¼Œç•«é¢è¦é©åˆä½œç‚ºå»£å‘Šä¸»è¦–è¦ºï¼Œå»ºè­°é¿å…éåº¦æŠ½è±¡æˆ–ç„¡ä¸»é«”çš„æ§‹åœ–ã€‚
            """
            gpt_response = client.chat.completions.create(
                model="gpt-4-1106-preview",
                messages=[
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": idea_description}
                ]
            )
            prompt = gpt_response.choices[0].message.content.strip()
            print("[GPT prompt]", prompt)
        except Exception as gpt_error:
            return JSONResponse(content={"error": f"GPT éŒ¯èª¤ï¼š{str(gpt_error)}"}, status_code=500)

        # Step 3: ä½¿ç”¨ DALLÂ·E ç”Ÿæˆåœ–ç‰‡
        try:
            img_response = client.images.generate(
                model="dall-e-3",
                prompt=prompt,
                n=1,
                size="1024x1024"
            )
            image_url = img_response.data[0].url
        except Exception as dalle_error:
            return JSONResponse(content={"error": f"DALLÂ·E éŒ¯èª¤ï¼š{str(dalle_error)}"}, status_code=500)

        return JSONResponse(content={
            "new_messages": text_messages + [
                {"role": "assistant", "type": "image", "image_url": image_url} # é¡¯ç¤ºåœ–ç‰‡
            ]
        })
        
    except Exception as e:
        print("[ERROR] generate-image:", e)
        return JSONResponse(content={"error": str(e)}, status_code=500)


# API ï¼šä¸Šå‚³åœ–ç‰‡
@app.post("/upload-image")
async def upload_image(file: UploadFile = File(...)):
    file_extension = file.filename.split(".")[-1].lower()
    if file_extension not in ["png", "jpg", "jpeg"]:
        return JSONResponse(content={"error": "åªæ”¯æ´ PNGã€JPGã€JPEG æ ¼å¼"}, status_code=400)
    try:
        fileName = f"{uuid.uuid4().hex}.{file_extension}"
        file_path = os.path.join(UPLOAD_DIR, fileName)
        with open(file_path, "wb") as f:
            f.write(await file.read())
        from backend.s3_uploader import upload_image_to_epsondest
        status, fileName = upload_image_to_epsondest(file_path, fileName)
        if status != 200:
            return JSONResponse(content={"error": "ä¸Šå‚³ Epson å¤±æ•—"}, status_code=500)
        return {"code": 200, "fileName": fileName}
    except Exception as e:
        return {"code": 500, "error": str(e)}

@app.get("/view-image/{fileName}")
async def view_image(fileName: str):
    file_path = os.path.join(UPLOAD_DIR, fileName)
    if not os.path.exists(file_path):
        return JSONResponse(content={"error": "File not found"}, status_code=404)
    return FileResponse(file_path, media_type="image/jpeg")

# API ï¼šç”Ÿæˆäº”å€‹ PDFï¼Œæ¯å€‹æ‡‰ç”¨ä¸åŒæ’ç‰ˆæ–¹å¼
@app.post("/generate-multiple-pdfs")
async def generate_multiple_pdfs(
    image_filename: str = Form(...), #æª”åæˆç¨±
    content: str = Form(...), #æ–‡å­—å…§å®¹
    font_size: int = Form(18), #å­—é«”å¤§å°
    code: int = Form(200)
):
    try:
        width, height = A4
        pdf_urls = []
        # å®šç¾©äº”ç¨®æ’ç‰ˆæ–¹å¼çš„ä½ç½®
        positions = {
            "topLeft": (40, height - 40),
            "topRight": (width - 140, height - 40),
            "center": (width / 2 - 50, height / 2),
            "bottomLeft": (40, 40),
            "bottomRight": (width - 140, 40)
        }

        image_path = os.path.join(UPLOAD_DIR, image_filename)
        if not os.path.exists(image_path):
            return JSONResponse(content={"error": "åœ–ç‰‡æª”æ¡ˆä¸å­˜åœ¨"}, status_code=400)
        img = ImageReader(image_path)
        img_width, img_height = Image.open(image_path).size
        scale = max(width / img_width, height / img_height)
        new_width = img_width * scale
        new_height = img_height * scale
        img_x = (width - new_width) / 2
        img_y = (height - new_height) / 2
        # ç‚ºæ¯ç¨®æ’ç‰ˆç”Ÿæˆç¨ç«‹çš„ PDF
        for layout, (x, y) in positions.items():
            fileName = f"{uuid.uuid4().hex}_{layout}.pdf"
            file_path = os.path.join(PDF_DIR, fileName)
            c = canvas.Canvas(file_path, pagesize=A4)
            # è¨­ç½®èƒŒæ™¯åœ–
            c.drawImage(img, img_x, img_y, new_width, new_height, mask="auto")
            # åœ¨ä¸åŒä½ç½®é¡¯ç¤ºæ–‡å­—
            c.setFont("Helvetica-Bold", font_size)
            c.setFillColorRGB(1, 1, 1)  # ç™½è‰²æ–‡å­—ç¢ºä¿å¯è¦‹
            c.drawString(x, y, content)
            c.save()

            upload_status, upload_response = upload_image_to_epsondest(file_path, fileName)
            print(f"[INFO] Upload to Epson API: {upload_status} - {upload_response}")

            if upload_status != 200:
                return JSONResponse(content={"error": "ä¸Šå‚³ PDF åˆ° Epson å¤±æ•—"}, status_code=500)
            pdf_urls.append({
                "layout": layout,
                # "status": upload_status,
                "url": upload_response
            })
            os.remove(file_path)

        return JSONResponse(content={
            "pdf_urls": pdf_urls,
            "code":200
            })
    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)

@app.get("/view-pdf/{fileName}")
async def view_pdf(fileName: str):
    file_path = os.path.join(PDF_DIR, fileName)
    if not os.path.exists(file_path):
        return JSONResponse(content={"error": "File not found"}, status_code=404)
    return FileResponse(file_path, media_type="application/pdf")